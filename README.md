# Cookiecutter Scrapy Project

## Features

- Configurations for Scrapy Cloud
- Configurations for Proxy Services:
    - [Zyte Smart Proxy Manager](https://scrapinghub.com/?rfsn=4170080.0597ad)
    - [ScraperAPI](https://www.scraperapi.com/?fp_ref=patrick50)

## Requirements

- [Cookiecutter](https://pypi.org/project/cookiecutter/) for creating the project
- [Scrapy](https://pypi.org/project/Scrapy/) for running the spider locally
- [Shub](https://pypi.org/project/shub/) if you want to deploy to Scrapy Cloud

## Options

|option   |default  |description   | 
|---|---|---|
|project_name   |Scrapy Boilerplate   |basically the root folder name   |
|spider_name   |Scrapy Spider Example   |class name of the spider   |
|proxy_service   |Zyte Smart Proxy Manager   |the proxy service used   |
|deploy_to_scrapy_cloud   |y   |whether or not the project is to be deployed on scrapy cloud   |
|host_on_kaggle   |y   |whether or not the dataset is hosted on kaggle.com   |

## ToDos:

- Add Spidermon
    - Telegram configs & templates
    - Some basic monitors
- Maybe add Scrapy Poet?

## Also,  
You could [buy me a coffe](https://www.buymeacoffee.com/kleinp) if you wanted to. I'd really appreciate that.  
